{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8ed4dae5c650a9f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prerequisite:\n",
    "## Set Up Google Cloud account (billing, service, credentials)\n",
    "- If you are new to Google Cloud, create an account. \n",
    "- In the Google Cloud console, create a Google Cloud project. \n",
    "- Select IAM & Admin service from within this project in the Google Cloud dashboard, create service account and generate service account key. \n",
    "\n",
    "## [Set up a Python development environment that run on Google Cloud](https://cloud.google.com/python/docs/setup)\n",
    "- Install Python;\n",
    "- Use `venv` to create isolated Python environment;  \n",
    "- Install the Cloud Client Libraries for the Python development environment;\n",
    "- [Install and initialize the gcloud CLI.](https://cloud.google.com/sdk/docs/install-sdk)\n",
    "\n",
    "## [Install Vertex AI SDK for Python](https://cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk) \n",
    "- Vertex AI is a comprehensive, managed machine learning platform by Google Cloud that allows ML engineers to develop and maintain ML/AL models.\n",
    "- ```\n",
    "  pip install --upgrade google-cloud-aiplatform\n",
    "  ```\n",
    "- Enable all recommended Vertex AI APIs from Vertex AI dashboard, e.g. Gemini Pro via the Gemini API.     \n",
    "\n",
    "  \n",
    "## [Quickstart with Gemini API with Python](https://ai.google.dev/tutorials/python_quickstart)\n",
    "- You can either run Jupyter notebook on your local editor or run codes in Google Colab. \n",
    "- Getting-started/intro_gemini_python.ipynb [github](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb) | [More Ex1](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/send-multimodal-prompts?_gl=1*17is47x*_ga*MTY5MzM3MDc0My4xNjc3NjE4OTE4*_ga_WH2QY8WWF5*MTcxMTc1Mjg3Ni45LjEuMTcxMTc1Mzk1OS4wLjAuMA..&_ga=2.179362852.-1693370743.1677618918) | [Ex2](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afc1d6cc1f124358"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d10cebe5065846a3"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from vertexai.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    ")\n",
    "from vertexai.vision_models import (\n",
    "    Video\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T08:15:11.714907Z",
     "start_time": "2024-03-31T08:15:11.706743Z"
    }
   },
   "id": "56c44becbbcdf788"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the Gemini 1.0 Pro Vision Model\n",
    "`geminii-1.0-pro-vision` is a multimodal model that supports multimodal prompts. You can include text, image(s) and video in your prompt requests and get text or code response. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba3e5c31226cac0b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "multimodal_model = GenerativeModel(\"gemini-1.0-pro-vision\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:41:03.306967Z",
     "start_time": "2024-03-31T06:41:03.294995Z"
    }
   },
   "id": "6172b9794db239e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define helper functions\n",
    "Define helper functions to load and display images."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34a3644e314075d3"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "import IPython\n",
    "import time\n",
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "import pathlib\n",
    "import textwrap\n",
    "import IPython.display\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_images(\n",
    "    images: typing.Iterable[Image],\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    for image in images:\n",
    "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "        if pil_image.mode != \"RGB\":\n",
    "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "        image_width, image_height = pil_image.size\n",
    "        if max_width < image_width or max_height < image_height:\n",
    "            # Resize to display a smaller notebook image\n",
    "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "        IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "def get_url_from_gcs(gcs_uri: str) -> str:\n",
    "    # converts gcs uri to url for image display.\n",
    "    url = \"https://storage.googleapis.com/\" + gcs_uri.replace(\"gs://\", \"\").replace(\n",
    "        \" \", \"%20\"\n",
    "    )\n",
    "    return url\n",
    "\n",
    "\n",
    "def print_multimodal_prompt(contents: list):\n",
    "    \"\"\"\n",
    "    Given contents that would be sent to Gemini,\n",
    "    output the full multimodal prompt for ease of readability.\n",
    "    \"\"\"\n",
    "    for content in contents:\n",
    "        if isinstance(content, Image):\n",
    "            display_images([content])\n",
    "        elif isinstance(content, Part):\n",
    "            url = get_url_from_gcs(content.file_data.file_uri)\n",
    "            IPython.display.display(load_image_from_url(url))\n",
    "        else:\n",
    "            print(content)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T09:44:24.145755Z",
     "start_time": "2024-03-31T09:44:24.136079Z"
    }
   },
   "id": "f548759918e74732"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper functions for handling videos contents \n",
    "\n",
    "* display video inline\n",
    "* load video from uri\n",
    "* generate response based on prompt  \n",
    "* "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32320afc793e323e"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T09:44:55.973931Z",
     "start_time": "2024-03-31T09:44:55.964774Z"
    }
   },
   "id": "a0aa861f67aabd69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Display video in-line"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e254be69d64eeb4"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Video object>",
      "text/html": "<video src=\"https://storage.cloud.google.com/vlm-videos/dump_trash.mp4?authuser=1\" controls  >\n      Your browser does not support the <code>video</code> element.\n    </video>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_uri = \"gs://vlm-videos/dump_trash.mp4\"\n",
    "video_url = \"https://storage.cloud.google.com/\" + video_uri.replace(\"gs://\", \"\") + \"?authuser=1\"\n",
    "IPython.display.Video(video_url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T09:12:30.008347Z",
     "start_time": "2024-03-31T09:12:29.999710Z"
    }
   },
   "id": "de6d6a35aacadbf1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load video from uri"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb02858d1203d8ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "video = Part.from_uri(video_uri, mime_type=\"video/mp4\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b97ab61a075e153b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Generate text from a video file \n",
    "\n",
    "* Video must be passed in as a Cloud Storage URI starting with 'gs://' for `Part.from_uri(uri=\"gs://....)`.\n",
    "* The bucket that stores the file must be in the same Google Cloud project that is sending the request. You must also specify the `mime_type` field. The supported MIME type for video includes `video/mp4`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33f4105a215ccf1a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the following questions using the video only:\n",
    "What action was performed? \n",
    "\"\"\"\n",
    "content = [prompt, video]\n",
    "response = multimodal_model.generate_content(content)\n",
    "to_markdown(response.text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd5a7634b2e24170"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": ">  A hand came into the scene and threw the tomatoes into the trash one by one. Then the hand threw the empty bottle into the trash. Finally, the hand balled up the paper towel and threw it into the trash."
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the following questions using the video only:\n",
    "What action was performed? \n",
    "\"\"\"\n",
    "content = [prompt, video]\n",
    "response = multimodal_model.generate_content(content)\n",
    "to_markdown(response.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T09:45:01.851969Z",
     "start_time": "2024-03-31T09:45:01.850119Z"
    }
   },
   "id": "8c7f22ce772abb7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Break down response "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5e1248b69af64f2"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "['A hand came into the scene and threw the tomatoes into the trash one by one',\n 'Then the hand threw the empty bottle into the trash',\n 'Finally, the hand balled up the paper towel and threw it into the trash']"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [a.strip() for a in response.text.split('.') if len(a) > 0]\n",
    "actions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T09:55:21.419760Z",
     "start_time": "2024-03-31T09:55:21.410026Z"
    }
   },
   "id": "aadd1ae3fa2ae0c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d67ef9772e37ee09"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
