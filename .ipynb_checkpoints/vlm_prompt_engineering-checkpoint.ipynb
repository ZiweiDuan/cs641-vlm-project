{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8ed4dae5c650a9f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prerequisite:\n",
    "## Set Up Google Cloud account (billing, service, credentials)\n",
    "- If you are new to Google Cloud, create an account. \n",
    "- In the Google Cloud console, create a Google Cloud project. \n",
    "- Select IAM & Admin service from within this project in the Google Cloud dashboard, create service account and generate service account key. \n",
    "\n",
    "## [Set up a Python development environment that run on Google Cloud](https://cloud.google.com/python/docs/setup)\n",
    "- Install Python;\n",
    "- Use `venv` to create isolated Python environment;  \n",
    "- Install the Cloud Client Libraries for the Python development environment;\n",
    "- [Install and initialize the gcloud CLI.](https://cloud.google.com/sdk/docs/install-sdk)\n",
    "\n",
    "## [Install Vertex AI SDK for Python](https://cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk) \n",
    "- Vertex AI is a comprehensive, managed machine learning platform by Google Cloud that allows ML engineers to develop and maintain ML/AL models.\n",
    "- ```\n",
    "  pip install --upgrade google-cloud-aiplatform\n",
    "  ```\n",
    "- Enable all recommended Vertex AI APIs from Vertex AI dashboard, e.g. Gemini Pro via the Gemini API.     \n",
    "\n",
    "  \n",
    "## [Quickstart with Gemini API with Python](https://ai.google.dev/tutorials/python_quickstart)\n",
    "- You can either run Jupyter notebook on your local editor or run codes in Google Colab. \n",
    "- Getting-started/intro_gemini_python.ipynb [github](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb) | [More Ex1](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/send-multimodal-prompts?_gl=1*17is47x*_ga*MTY5MzM3MDc0My4xNjc3NjE4OTE4*_ga_WH2QY8WWF5*MTcxMTc1Mjg3Ni45LjEuMTcxMTc1Mzk1OS4wLjAuMA..&_ga=2.179362852.-1693370743.1677618918) | [Ex2](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afc1d6cc1f124358"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d10cebe5065846a3"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from vertexai.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:37:55.873428Z",
     "start_time": "2024-03-31T06:37:54.530812Z"
    }
   },
   "id": "56c44becbbcdf788"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the Gemini 1.0 Pro Vision Model\n",
    "`geminii-1.0-pro-vision` is a multimodal model that supports multimodal prompts. You can include text, image(s) and video in your prompt requests and get text or code response. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba3e5c31226cac0b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "multimodal_model = GenerativeModel(\"gemini-1.0-pro-vision\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:41:03.306967Z",
     "start_time": "2024-03-31T06:41:03.294995Z"
    }
   },
   "id": "6172b9794db239e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define helper functions\n",
    "Define helper functions to load and display images."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34a3644e314075d3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import IPython\n",
    "import time\n",
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_images(\n",
    "    images: typing.Iterable[Image],\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    for image in images:\n",
    "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "        if pil_image.mode != \"RGB\":\n",
    "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "        image_width, image_height = pil_image.size\n",
    "        if max_width < image_width or max_height < image_height:\n",
    "            # Resize to display a smaller notebook image\n",
    "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "        IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "def get_url_from_gcs(gcs_uri: str) -> str:\n",
    "    # converts gcs uri to url for image display.\n",
    "    url = \"https://storage.googleapis.com/\" + gcs_uri.replace(\"gs://\", \"\").replace(\n",
    "        \" \", \"%20\"\n",
    "    )\n",
    "    return url\n",
    "\n",
    "\n",
    "def print_multimodal_prompt(contents: list):\n",
    "    \"\"\"\n",
    "    Given contents that would be sent to Gemini,\n",
    "    output the full multimodal prompt for ease of readability.\n",
    "    \"\"\"\n",
    "    for content in contents:\n",
    "        if isinstance(content, Image):\n",
    "            display_images([content])\n",
    "        elif isinstance(content, Part):\n",
    "            url = get_url_from_gcs(content.file_data.file_uri)\n",
    "            IPython.display.display(load_image_from_url(url))\n",
    "        else:\n",
    "            print(content)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:47:38.040079Z",
     "start_time": "2024-03-31T06:47:38.002564Z"
    }
   },
   "id": "f548759918e74732"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate text from a video file \n",
    "Specify the Cloud Storage URI of the video to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that is sending the request. You must also specify the `mime_type` field. The supported MIME type for video includes `video/mp4`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e254be69d64eeb4"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Video object>",
      "text/html": "<video src=\"./res/dump_trash.mp4\" controls  >\n      Your browser does not support the <code>video</code> element.\n    </video>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "file_path = \"./res/dump_trash.mp4\"\n",
    "Video(file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:52:26.733460Z",
     "start_time": "2024-03-31T07:52:26.707309Z"
    }
   },
   "id": "c54cfa2d43c426f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<video controls src=\"./res/dump_trash.mp4\">animation</video>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78591c70476a23d3"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free...')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e62ed7b40ee94def8206006b5cb75c87"
      }
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import Video\n",
    "Video.from_file(\"./res/dump_trash.mp4\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:55:05.050771Z",
     "start_time": "2024-03-31T07:55:04.993233Z"
    }
   },
   "id": "2ca15db69fcb2139"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8c7f22ce772abb7a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
